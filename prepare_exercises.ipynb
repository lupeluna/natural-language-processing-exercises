{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import prepare\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/guadalupeluna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guadalupeluna/Desktop/code-up-data-science/natural-language-processing-exercises/acquire.py:141: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 141 of the file /Users/guadalupeluna/Desktop/code-up-data-science/natural-language-processing-exercises/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n"
     ]
    }
   ],
   "source": [
    "# define categories\n",
    "categories = [\"business\", \"sports\", \"technology\", \"entertainment\"]\n",
    "\n",
    "# use get_all_new_article function from acquire.py file \n",
    "\n",
    "news_df = acquire.get_all_news_articles(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliance Industries vaccinates 98% of workers,...</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will most likely not be on future earnings c...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speculation around our plans for crypto not tr...</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Musk criticises Apple's 'walled garden', cobal...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Govt may lower import duty on EVs if Tesla man...</td>\n",
       "      <td>The government is open to consider reducing im...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Reliance Industries vaccinates 98% of workers,...   \n",
       "1  I will most likely not be on future earnings c...   \n",
       "2  Speculation around our plans for crypto not tr...   \n",
       "3  Musk criticises Apple's 'walled garden', cobal...   \n",
       "4  Govt may lower import duty on EVs if Tesla man...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Reliance Industries has said in a statement th...  business  \n",
       "1  Tesla CEO and the world's second-richest perso...  business  \n",
       "2  Amazon on Monday denied speculations that it w...  business  \n",
       "3  Tesla's billionaire CEO Elon Musk criticised A...  business  \n",
       "4  The government is open to consider reducing im...  business  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the head of dataframe\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reliance Industries has said in a statement that over 98% of its workers have received at least one dose of COVID-19 vaccine so far. The billionaire Mukesh Ambani-led conglomerate had over 2.36 lakh employees, of March 31. Besides Reliance, Hindustan Unilever has also given at least one shot to 90% of employees, while Infosys inoculated 59% employees and TCS 70%.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets use the content of first news item as 'article' to test my functions\n",
    "\n",
    "article = news_df.content[0]\n",
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    string = re.sub(r'[^\\w\\s]', '', string).lower()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reliance industries has said in a statement that over 98 of its workers have received at least one dose of covid19 vaccine so far the billionaire mukesh ambaniled conglomerate had over 236 lakh employees of march 31 besides reliance hindustan unilever has also given at least one shot to 90 of employees while infosys inoculated 59 employees and tcs 70'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function defined above\n",
    "\n",
    "basic_clean(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and returns a tokenized string.\n",
    "    \n",
    "    '''\n",
    "    # create the tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    # Use the tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reliance Industries has said in a statement that over 98 % of its workers have received at least one dose of COVID-19 vaccine so far. The billionaire Mukesh Ambani-led conglomerate had over 2.36 lakh employees , of March 31. Besides Reliance , Hindustan Unilever has also given at least one shot to 90 % of employees , while Infosys inoculated 59 % employees and TCS 70 % .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function defined above\n",
    "\n",
    "tokenize(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Use the stemmer to stem each word in the list of words we created by using split.\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    # Join our lists of words into a string again and assign to a variable.\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'relianc industri ha said in a statement that over 98% of it worker have receiv at least one dose of covid-19 vaccin so far. the billionair mukesh ambani-l conglomer had over 2.36 lakh employees, of march 31. besid reliance, hindustan unilev ha also given at least one shot to 90% of employees, while infosi inocul 59% employe and tc 70%.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function defined above\n",
    "\n",
    "stem(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reliance Industries ha said in a statement that over 98% of it worker have received at least one dose of COVID-19 vaccine so far. The billionaire Mukesh Ambani-led conglomerate had over 2.36 lakh employees, of March 31. Besides Reliance, Hindustan Unilever ha also given at least one shot to 90% of employees, while Infosys inoculated 59% employee and TCS 70%.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function defined above\n",
    "\n",
    "lemmatize(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    \n",
    "    # Add in 'extra_words' to stopword_list.\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reliance Industries said statement 98% workers received least one dose COVID-19 vaccine far. The billionaire Mukesh Ambani-led conglomerate 2.36 lakh employees, March 31. Besides Reliance, Hindustan Unilever also given least one shot 90% employees, Infosys inoculated 59% employees TCS 70%.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function defined above\n",
    "\n",
    "remove_stopwords(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliance Industries vaccinates 98% of workers,...</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will most likely not be on future earnings c...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speculation around our plans for crypto not tr...</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Musk criticises Apple's 'walled garden', cobal...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Govt may lower import duty on EVs if Tesla man...</td>\n",
       "      <td>The government is open to consider reducing im...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Reliance Industries vaccinates 98% of workers,...   \n",
       "1  I will most likely not be on future earnings c...   \n",
       "2  Speculation around our plans for crypto not tr...   \n",
       "3  Musk criticises Apple's 'walled garden', cobal...   \n",
       "4  Govt may lower import duty on EVs if Tesla man...   \n",
       "\n",
       "                                             content  category  \n",
       "0  Reliance Industries has said in a statement th...  business  \n",
       "1  Tesla CEO and the world's second-richest perso...  business  \n",
       "2  Amazon on Monday denied speculations that it w...  business  \n",
       "3  Tesla's billionaire CEO Elon Musk criticised A...  business  \n",
       "4  The government is open to consider reducing im...  business  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check head of my news_df dataframe:\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     reliance industry ha said statement 98 worker ...\n",
       "1     tesla ceo world secondrichest person elon musk...\n",
       "2     amazon monday denied speculation wa looking ac...\n",
       "3     tesla billionaire ceo elon musk criticised app...\n",
       "4     government open consider reducing import duty ...\n",
       "                            ...                        \n",
       "93    reacting rumour tiff cast show taarak mehta ka...\n",
       "94    actor atul kulkarni share screen space actor a...\n",
       "95    veteran actress savita bajaj unwell facing fin...\n",
       "96    filmmaker aditya vikram senguptas upon time ca...\n",
       "97    bigg bos 14 contestant jaan kumar sanu spoke i...\n",
       "Name: content, Length: 98, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use all the functions to see if they work on news_df's content column\n",
    "\n",
    "news_df['content'].apply(basic_clean)\\\n",
    ".apply(tokenize)\\\n",
    ".apply(lemmatize)\\\n",
    ".apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guadalupeluna/Desktop/code-up-data-science/natural-language-processing-exercises/acquire.py:51: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 51 of the file /Users/guadalupeluna/Desktop/code-up-data-science/natural-language-processing-exercises/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n"
     ]
    }
   ],
   "source": [
    "codeup_df = acquire.acquire_codeup_blog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>published_date</th>\n",
       "      <th>blog_image</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>September 30, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>October 31, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>October 17, 2018</td>\n",
       "      <td>https://codeup.com/wp-content/uploads/2018/10/...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>August 14, 2018</td>\n",
       "      <td>None</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>August 14, 2018</td>\n",
       "      <td>None</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      published_date  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!  September 30, 2018   \n",
       "1                                 Data Science Myths    October 31, 2018   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...    October 17, 2018   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair     August 14, 2018   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...     August 14, 2018   \n",
       "\n",
       "                                          blog_image  \\\n",
       "0  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "1  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "2  https://codeup.com/wp-content/uploads/2018/10/...   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                             content  \n",
       "0  The rumors are true! The time has arrived. Cod...  \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...  \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...  \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...  \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    df['stemmed'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(stem)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    df['lemmatized'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(lemmatize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\n",
    "    \n",
    "    return df[['title', column,'clean', 'stemmed', 'lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reliance Industries vaccinates 98% of workers,...</td>\n",
       "      <td>Reliance Industries has said in a statement th...</td>\n",
       "      <td>reliance industries said statement 98 workers ...</td>\n",
       "      <td>relianc industri said statement 98 worker rece...</td>\n",
       "      <td>reliance industry said statement 98 worker rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Speculation around our plans for crypto not tr...</td>\n",
       "      <td>Amazon on Monday denied speculations that it w...</td>\n",
       "      <td>amazon monday denied speculations looking acce...</td>\n",
       "      <td>amazon monday deni specul wa look accept bitco...</td>\n",
       "      <td>amazon monday denied speculation wa looking ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musk criticises Apple's 'walled garden', cobal...</td>\n",
       "      <td>Tesla's billionaire CEO Elon Musk criticised A...</td>\n",
       "      <td>teslas billionaire ceo elon musk criticised ap...</td>\n",
       "      <td>tesla billionair ceo elon musk criticis appl t...</td>\n",
       "      <td>tesla billionaire ceo elon musk criticised app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I will most likely not be on future earnings c...</td>\n",
       "      <td>Tesla CEO and the world's second-richest perso...</td>\n",
       "      <td>tesla ceo worlds secondrichest person elon mus...</td>\n",
       "      <td>tesla ceo world secondrichest person elon musk...</td>\n",
       "      <td>tesla ceo world secondrichest person elon musk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Govt may lower import duty on EVs if Tesla man...</td>\n",
       "      <td>The government is open to consider reducing im...</td>\n",
       "      <td>government open consider reducing import duty ...</td>\n",
       "      <td>govern open consid reduc import duti offer inc...</td>\n",
       "      <td>government open consider reducing import duty ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Reliance Industries vaccinates 98% of workers,...   \n",
       "1  Speculation around our plans for crypto not tr...   \n",
       "2  Musk criticises Apple's 'walled garden', cobal...   \n",
       "3  I will most likely not be on future earnings c...   \n",
       "4  Govt may lower import duty on EVs if Tesla man...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Reliance Industries has said in a statement th...   \n",
       "1  Amazon on Monday denied speculations that it w...   \n",
       "2  Tesla's billionaire CEO Elon Musk criticised A...   \n",
       "3  Tesla CEO and the world's second-richest perso...   \n",
       "4  The government is open to consider reducing im...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  reliance industries said statement 98 workers ...   \n",
       "1  amazon monday denied speculations looking acce...   \n",
       "2  teslas billionaire ceo elon musk criticised ap...   \n",
       "3  tesla ceo worlds secondrichest person elon mus...   \n",
       "4  government open consider reducing import duty ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  relianc industri said statement 98 worker rece...   \n",
       "1  amazon monday deni specul wa look accept bitco...   \n",
       "2  tesla billionair ceo elon musk criticis appl t...   \n",
       "3  tesla ceo world secondrichest person elon musk...   \n",
       "4  govern open consid reduc import duti offer inc...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  reliance industry said statement 98 worker rec...  \n",
       "1  amazon monday denied speculation wa looking ac...  \n",
       "2  tesla billionaire ceo elon musk criticised app...  \n",
       "3  tesla ceo world secondrichest person elon musk...  \n",
       "4  government open consider reducing import duty ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the function defined above for news_df's content column.\n",
    "\n",
    "prep_article_data(news_df, 'content', extra_words = ['ha'], exclude_words = ['no']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
